{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- 🤝 Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- 🤝 Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# 🤝 Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank)).\n",
        "\n",
        "> You do not need to run the following cells if you are running this notebook locally. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgFAXWVW3wm",
        "outputId": "636db35c-f05a-4038-ec7a-02360bef2dae"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain langchain-openai langchain-cohere rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqYM4Eoxcov"
      },
      "source": [
        "We're also going to be leveraging [Qdrant's](https://qdrant.tech/documentation/frameworks/langchain/) (pronounced \"Quadrant\") VectorDB in \"memory\" mode (so we can leverage it locally in our colab environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(For Activity #1) Setup for LangChain tracing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangChain API key: \")\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAGAS-Eval-Session-13\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0pDRFEWSXvh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using some reviews from the 4 movies in the John Wick franchise today to explore the different retrieval strategies.\n",
        "\n",
        "These were obtained from IMDB, and are available in the [AIM Data Repository](https://github.com/AI-Maker-Space/DataRepository)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXKHcZmKzDwT"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We can simply `wget` these from GitHub.\n",
        "\n",
        "You could use any review data you wanted in this step - just be careful to make sure your metadata is aligned with your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "0ce6514e-2479-4001-af24-824f987ce599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-18 15:50:04--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8001::154, 2606:50c0:8003::154, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19628 (19K) [text/plain]\n",
            "Saving to: ‘john_wick_1.csv’\n",
            "\n",
            "john_wick_1.csv     100%[===================>]  19.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-18 15:50:05 (45.3 MB/s) - ‘john_wick_1.csv’ saved [19628/19628]\n",
            "\n",
            "--2025-05-18 15:50:06--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8001::154, 2606:50c0:8003::154, 2606:50c0:8000::154, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8001::154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14747 (14K) [text/plain]\n",
            "Saving to: ‘john_wick_2.csv’\n",
            "\n",
            "john_wick_2.csv     100%[===================>]  14.40K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-05-18 15:50:06 (17.8 MB/s) - ‘john_wick_2.csv’ saved [14747/14747]\n",
            "\n",
            "--2025-05-18 15:50:07--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8003::154, 2606:50c0:8002::154, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13888 (14K) [text/plain]\n",
            "Saving to: ‘john_wick_3.csv’\n",
            "\n",
            "john_wick_3.csv     100%[===================>]  13.56K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-05-18 15:50:07 (7.68 MB/s) - ‘john_wick_3.csv’ saved [13888/13888]\n",
            "\n",
            "--2025-05-18 15:50:08--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8000::154, 2606:50c0:8002::154, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8003::154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15109 (15K) [text/plain]\n",
            "Saving to: ‘john_wick_4.csv’\n",
            "\n",
            "john_wick_4.csv     100%[===================>]  14.75K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-05-18 15:50:08 (23.7 MB/s) - ‘john_wick_4.csv’ saved [15109/15109]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv -O john_wick_1.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv -O john_wick_2.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv -O john_wick_3.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv -O john_wick_4.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today.\n",
        "\n",
        "- Self-Query: Wants as much metadata as we can provide\n",
        "- Time-weighted: Wants temporal data\n",
        "\n",
        "> NOTE: While we're creating a temporal relationship based on when these movies came out for illustrative purposes, it needs to be clear that the \"time-weighting\" in the Time-weighted Retriever is based on when the document was *accessed* last - not when it was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "chunkSizes = []\n",
        "for doc in documents:\n",
        "    chunkSizes.append(len(doc.page_content))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example list of integers\n",
        "data = chunkSizes\n",
        "\n",
        "# Create x-axis values (indices of the list)\n",
        "x = range(len(data))\n",
        "\n",
        "# Plot vertical lines for each integer\n",
        "for i, value in enumerate(data):\n",
        "    plt.plot([i, i], [0, value], 'b-')  # 'b-' means blue line\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Vertical Lines for List Values')\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2025, 5, 15, 15, 50, 9, 139670)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"JohnWick\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWick\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "# NOTE: I refactored this method to facilitate the tracing proocess\n",
        "#       for the RAGAS evaluations later.\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.callbacks.tracers.langchain import LangChainTracer\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "\n",
        "def make_chat_model(retriever_name: str = None, model_name: str = \"gpt-4o\") -> ChatOpenAI:\n",
        "    if retriever_name:\n",
        "        tracer = LangChainTracer(\n",
        "            project_name=f\"ragas-eval-{retriever_name}\",\n",
        "            tags=[retriever_name, \"retriever\", \"session-13\", model_name]\n",
        "        )\n",
        "        callback_manager = CallbackManager([tracer])\n",
        "        return ChatOpenAI(\n",
        "            model=model_name,\n",
        "            temperature=0,\n",
        "            max_tokens=8192,\n",
        "            callback_manager=callback_manager\n",
        "        )\n",
        "    else:\n",
        "        return ChatOpenAI(\n",
        "            model=model_name,\n",
        "            temperature=0,\n",
        "            max_tokens=1024\n",
        "        )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5p/gq47dsys3k5663k1r5z8s3c40000gn/T/ipykernel_77341/3725807027.py:22: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  return ChatOpenAI(\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "chat_model = make_chat_model()\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the context provided, it seems that people generally liked \"John Wick.\" The reviews for the first film are mostly positive, highlighting its action sequences, Keanu Reeves\\' performance, and the film\\'s stylish and unique approach to the action genre. While there are a few mixed opinions, the overall sentiment is favorable, with many reviewers recommending the film to action fans and praising its entertainment value.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. Here is the URL to that review:\\n\\n- [John Wick 3 Review by ymyuseda](https://www.imdb.com/review/rw4854296/?ref_=tt_urv)'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the movie \"John Wick,\" the main character, John Wick, is a retired hitman who is drawn back into the criminal underworld after a group of gangsters kill his dog and steal his car. The dog was a final gift from his recently deceased wife, and its death pushes him to seek revenge. The gangsters, led by a young Russian-American, are unaware of Wick\\'s lethal skills and his past as a legendary assassin. As Wick seeks vengeance, he becomes the target of numerous hitmen, leading to a series of intense and violent confrontations. The film is known for its stylish action sequences and the portrayal of a criminal underworld where Wick is both feared and respected.'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the context provided, opinions on the John Wick series appear to be mixed. Some reviews are very positive, praising the action sequences, style, and simplicity of the plot, particularly for the first movie. For example, one review describes \"John Wick 1\" as a \"smoothest action film\" and highly recommends it for action fans. Another review appreciates its \"kinetic, concise, and stylish\" nature.\\n\\nHowever, there are also negative reviews, particularly for the later movies in the series. For instance, \"John Wick 3\" is criticized for being \"boring, dull, and full of stereotypes,\" and \"John Wick 4\" is described as \"almost three hours of nothing\" with a weak narrative.\\n\\nOverall, while some people seem to enjoy the John Wick movies, especially the first one, others find the later installments lacking in plot and overly reliant on action.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, there are no reviews with a rating of 10.'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I don\\'t know the specific plot details of \"John Wick\" based on the provided context. The context includes reviews of the John Wick series, but it does not provide a summary or specific events from the first movie.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse - but the `I don't know` isn't great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the context provided, it seems that people generally liked the first \"John Wick\" film. The reviews highlight its unique and stylish approach to action, the performance of Keanu Reeves, and the film\\'s ability to entertain with its intense and well-choreographed action sequences. The reviewers recommend it highly, especially for action fans, and describe it as a standout film in the genre.'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is: /review/rw4854296/?ref_=tt_urv.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the movie \"John Wick,\" the main character, John Wick, is an ex-hitman who comes out of retirement to seek revenge on the gangsters who killed his dog and stole his car. The dog was a final gift from his recently deceased wife, making the loss deeply personal. As he pursues vengeance, Wick becomes the target of numerous hitmen due to his lethal reputation and the price on his head. The film is known for its intense action sequences, stylish stunts, and the portrayal of Wick as a relentless and skilled assassin.'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the context provided, it seems that the \"John Wick\" series is generally well-received by audiences. Many reviews highlight the films\\' action sequences, style, and Keanu Reeves\\' performance positively. The first film, in particular, is praised for its unique approach to the action genre and has been described as a surprise hit. However, there are some mixed reviews, especially for the later installments, with some viewers feeling that the series has become repetitive or lacks depth. Overall, the series appears to have a strong fan base and is generally liked, but not universally loved by everyone.'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is: [/review/rw4854296/?ref_=tt_urv](https://www.imdb.com/review/rw4854296/?ref_=tt_urv).'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the movie \"John Wick,\" the plot revolves around the character John Wick, played by Keanu Reeves, who is a retired hitman. The story begins with John grieving the loss of his wife. After her death, he receives a puppy as a final gift from her to help him cope with his grief. However, his life takes a violent turn when a group of thugs, led by a young Russian-American, break into his home, steal his car, and kill his dog. This act of violence pulls John Wick out of retirement as he seeks revenge against those who wronged him. The film is known for its stylish action sequences, with John Wick waging a one-man war against the Russian Mafia, showcasing his skills as a legendary assassin. The movie is praised for its simplicity, intense action, and Keanu Reeves\\' performance.'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5p/gq47dsys3k5663k1r5z8s3c40000gn/T/ipykernel_77341/3574430551.py:8: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
            "  parent_document_vectorstore = Qdrant(\n"
          ]
        }
      ],
      "source": [
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = Qdrant(\n",
        "    collection_name=\"full_documents\", embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the context provided, it seems that opinions on the John Wick series are mixed. Some people, like the author of the second document, find the series to be consistently well-received and even consider \"John Wick: Chapter 4\" to be the best of the series. On the other hand, the author of the first document had a very negative opinion of \"John Wick 4,\" describing it as \"horrible\" and criticizing various aspects of the film. The third document shows a positive review of the first John Wick movie, highlighting its action and emotional setup. Overall, while there are some negative opinions, there are also strong positive reviews, suggesting that many people do generally like the John Wick series.'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is: /review/rw4854296/?ref_=tt_urv.'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the first \"John Wick\" movie, John Wick, played by Keanu Reeves, is a retired hitman who comes out of retirement to seek vengeance after gangsters kill his dog and steal his car. The dog was a final gift from his recently deceased wife, and its death pushes him to track down those responsible. As he seeks revenge, he becomes the target of numerous hitmen due to a bounty placed on his head.\\n\\nIn \"John Wick: Chapter 2,\" the story continues with John Wick being forced back into the world of assassins to repay an old debt. The movie begins with him retrieving his stolen car, and he is soon drawn into a conflict involving the Assassin\\'s Guild. The sequel involves a lot of action, with John Wick traveling to various locations and facing off against numerous assassins.'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the context provided, it seems that people generally liked \"John Wick.\" The reviews for the first film are mostly positive, with high ratings and praise for its action sequences, style, and Keanu Reeves\\' performance. There are some mixed reviews, but the overall sentiment appears to be favorable. Additionally, the series as a whole is noted for being consistent and well-received, with the fourth installment also receiving positive feedback despite some criticism.'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is: [/review/rw4854296/?ref_=tt_urv](https://www.imdb.com/review/rw4854296/?ref_=tt_urv).'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the movie \"John Wick,\" the main character, John Wick, is a retired hitman who is drawn back into the criminal underworld after a group of Russian mobsters kill his dog and steal his car. The dog was a final gift from his recently deceased wife, and its death leaves him with nothing to lose. Fueled by a desire for revenge, Wick embarks on a violent rampage against those who wronged him. The film is known for its intense action sequences, stylish choreography, and the portrayal of a criminal underworld where Wick is both feared and respected.'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!\n",
        "\n",
        "> NOTE: You do not need to run this cell if you're running this locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHeB-yGXneL",
        "outputId": "efc59105-518a-4134-9228-d98b8a97e08e"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWickSemantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the context provided, it seems that people generally liked the John Wick series. The reviews for the first film are particularly positive, with high ratings and praise for its action sequences and style. While there are some mixed reviews for the third film, the overall sentiment across the series appears to be favorable, with the fourth installment also receiving positive feedback.'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. Here is the URL to that review:\\n\\n- [Review by ymyuseda](https://www.imdb.com/review/rw4854296/?ref_=tt_urv)'"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the movie \"John Wick,\" the main character, John Wick, played by Keanu Reeves, is a retired assassin who comes out of retirement to seek revenge on the people who wronged him. The story begins with the death of his beloved wife, and shortly after, a group of thugs led by the son of a Russian gangster break into his house, steal his car, and kill his dog, which was a final gift from his wife. This act of violence prompts John Wick to unleash his skills as a legendary hitman to track down and take revenge on those responsible. The film is known for its intense action sequences, stylish stunts, and the portrayal of a criminal underworld.'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# 🤝 Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### 🏗️ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retriever Evaluation\n",
        "\n",
        "### Generating the Golden Dataset\n",
        "The following code will use RAGAS to generate 10 questions from the base knowledge (`documents`) loaded earlier in this notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a29c910d64e4bcca496cb96f321d762",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/44 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c56e503dc7814d98b5ff6edea537dcaa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node 65b13e5b-b0a8-4690-9db0-206697a29bce does not have a summary. Skipping filtering.\n",
            "Node 2bcfecdc-8d55-457f-b945-bb6b4a2e1ea2 does not have a summary. Skipping filtering.\n",
            "Node ef37caa7-f382-4e73-a777-6aff367fbb04 does not have a summary. Skipping filtering.\n",
            "Node 68a4b753-5a5e-4d62-85c4-65b51840c752 does not have a summary. Skipping filtering.\n",
            "Node faad2dfb-d1eb-4d41-8250-35bd6da361ff does not have a summary. Skipping filtering.\n",
            "Node 76c8270e-cfa1-41c2-a022-2efeb137f882 does not have a summary. Skipping filtering.\n",
            "Node 880822ec-dc79-4143-adfb-055612438496 does not have a summary. Skipping filtering.\n",
            "Node ab9fcb7f-7554-4dab-a682-6717108182d7 does not have a summary. Skipping filtering.\n",
            "Node ec284fb3-a865-4d44-bf7c-730ed0bd84f9 does not have a summary. Skipping filtering.\n",
            "Node 299d5d24-071b-4037-aed9-a5679096431d does not have a summary. Skipping filtering.\n",
            "Node dfa06cc8-6cf7-415e-9766-097496bca4d8 does not have a summary. Skipping filtering.\n",
            "Node 5c52f1a4-128d-43de-948c-29011c54f526 does not have a summary. Skipping filtering.\n",
            "Node 3c4f6b23-c611-4b38-9899-ab840e7beb7b does not have a summary. Skipping filtering.\n",
            "Node 2c3ac3d7-6855-4b01-b426-a9a3bc73c2be does not have a summary. Skipping filtering.\n",
            "Node 69617ca5-c99e-4352-90df-c357b8841a82 does not have a summary. Skipping filtering.\n",
            "Node 703c0eff-e2cc-4fae-a176-ef8f091f415a does not have a summary. Skipping filtering.\n",
            "Node 6d6a99fd-6091-4e18-b65d-436c7a637f1d does not have a summary. Skipping filtering.\n",
            "Node 40597ef5-5d29-40ff-a6fd-b8400e50f52e does not have a summary. Skipping filtering.\n",
            "Node 9f6ad116-3e22-4a0f-a857-58666b2873b8 does not have a summary. Skipping filtering.\n",
            "Node f4fc2558-e063-42c6-9c37-77c9787d236e does not have a summary. Skipping filtering.\n",
            "Node 71ccccc7-8bc0-4a02-a1d5-61d0efe8380b does not have a summary. Skipping filtering.\n",
            "Node a5df43ea-9737-448c-b2f9-15757220b06f does not have a summary. Skipping filtering.\n",
            "Node 49770f96-53f7-404b-bf79-0d1ba756ce27 does not have a summary. Skipping filtering.\n",
            "Node 2db32c1a-3515-47d6-8081-1bf812b076e2 does not have a summary. Skipping filtering.\n",
            "Node 5519d03a-93d2-4c5b-ba71-4e568769d719 does not have a summary. Skipping filtering.\n",
            "Node bda9181d-441f-4ff2-a197-f5565fdd634b does not have a summary. Skipping filtering.\n",
            "Node 7270b202-4286-4283-9a97-da5bc9221bc1 does not have a summary. Skipping filtering.\n",
            "Node a6b1899e-1169-462e-8608-5165bf060768 does not have a summary. Skipping filtering.\n",
            "Node e75ce6fe-8f45-492b-b0a3-453f4bdc5e2b does not have a summary. Skipping filtering.\n",
            "Node b79d6b9f-4781-4aab-b89d-ed3ee1f98c53 does not have a summary. Skipping filtering.\n",
            "Node 52495f4f-02b5-4972-9655-cfcd9602f2a2 does not have a summary. Skipping filtering.\n",
            "Node f0a3d827-4665-4eb6-b32c-1296abe4deef does not have a summary. Skipping filtering.\n",
            "Node 219335a9-bf9b-4633-93a8-93488b93961e does not have a summary. Skipping filtering.\n",
            "Node 7dd9f14d-15e1-46bc-98e4-258970276ffd does not have a summary. Skipping filtering.\n",
            "Node 8f8760dc-211d-4933-9bbd-20d8dfbb411b does not have a summary. Skipping filtering.\n",
            "Node a2398007-ed82-4fc3-9d1a-56a2cfecbfd7 does not have a summary. Skipping filtering.\n",
            "Node 6e8e2d96-af29-426d-912e-4648d3381f5a does not have a summary. Skipping filtering.\n",
            "Node f6f230fc-c7e4-49d2-8b43-2d8e2c9974c7 does not have a summary. Skipping filtering.\n",
            "Node ef7aa55e-3f44-42d4-83e8-246b8c9d6365 does not have a summary. Skipping filtering.\n",
            "Node 40205063-f255-4a4e-85f1-2657577c2c51 does not have a summary. Skipping filtering.\n",
            "Node 888acbf8-f247-468a-8061-91ef96813a08 does not have a summary. Skipping filtering.\n",
            "Node 0712133c-67b8-4ad7-ab6d-2172656b9b6c does not have a summary. Skipping filtering.\n",
            "Node 7ad693b8-bde2-4fc5-889a-c42f13abe1c8 does not have a summary. Skipping filtering.\n",
            "Node af29bbd4-0b38-47fa-8147-887b3d050d23 does not have a summary. Skipping filtering.\n",
            "Node e934e2d2-487c-4487-bc21-f5e80f300c2c does not have a summary. Skipping filtering.\n",
            "Node 8ddc5304-eb15-41e8-a45f-15c9fb403186 does not have a summary. Skipping filtering.\n",
            "Node a14faa5d-43c9-4b02-a3a1-ed016c453c29 does not have a summary. Skipping filtering.\n",
            "Node d9eae3df-2355-493a-a292-c1928a289fa1 does not have a summary. Skipping filtering.\n",
            "Node bd004def-9244-4a5c-872c-a42633935046 does not have a summary. Skipping filtering.\n",
            "Node abb5dfb1-5426-4743-abb4-cd6909a737c7 does not have a summary. Skipping filtering.\n",
            "Node 525280b0-7737-42e9-85b7-fdfcfdb88e64 does not have a summary. Skipping filtering.\n",
            "Node 3ad1a83e-06fd-4f46-a6ea-0a64a5209dae does not have a summary. Skipping filtering.\n",
            "Node 1f73015e-fd9e-4ce3-8e72-34410fa0d447 does not have a summary. Skipping filtering.\n",
            "Node abcf6987-0c2b-40be-a768-06c60b2dd061 does not have a summary. Skipping filtering.\n",
            "Node bfe7d4db-57ef-49d3-8c58-2e8820f38be2 does not have a summary. Skipping filtering.\n",
            "Node bc1099db-e9ef-4028-9d68-0b65004dcf4c does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18a2049754ec4397981fee7d8c437aa8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/244 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-R7FhOpnBh8AV6HY4M573NtwE on tokens per min (TPM): Limit 30000, Used 29960, Requested 585. Please try again in 1.09s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce387ba42e774dabb21a9e21af2edc4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9255a2fa0f64e69baf038647027fc53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0683313040274a8e9f2513885313ddf1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f40c8003f6f45a4b2bca8898ab16edb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: How does the plot of John Wick compare to Liam Neeson's role in Taken?\n",
            "GT: The plot of John Wick can be described as similar to Taken, but instead of Liam Neeson, it features Keanu Reeves, and instead of his daughter, it's his dog. Both films involve the protagonist seeking revenge for something they loved being taken from them.\n",
            "————————————————————————————————————————————————————————————\n",
            "Q: What has been the reception of the 'John Wick' film series, particularly with the release of its fourth installment?\n",
            "GT: The 'John Wick' film series has been immensely successful, with the fourth installment scoring highly at the cinemas. The previous three films are apparently loved by audiences worldwide.\n",
            "————————————————————————————————————————————————————————————\n",
            "Q: Wut makes Keanu's performnce in John Wick so special, even tho the story is simpl?\n",
            "GT: Keanu's performance in John Wick is special because the film, directed by Chad Stahelski, features real virtuoso action sequences and well-made choreographies. Unlike today's action movies, it doesn't use quick-cuts or shaky cameras, allowing viewers to actually see what's going on.\n",
            "————————————————————————————————————————————————————————————\n",
            "Q: What John Wick do when them mobsters mess with him and his dog?\n",
            "GT: When John Wick and his dog fall victim to a scummy group of Russian mobsters, he emerges from his shell with vengeance on his mind, leading to plenty of stylized, visceral action scenes.\n",
            "————————————————————————————————————————————————————————————\n",
            "Q: How does the revenge theme in John Wick 2 compare to the one man army style of action movies from the 80s?\n",
            "GT: In John Wick 2, the revenge theme is intricately woven into the plot, focusing on the personal betrayal of the protagonist, John Wick. This theme is complemented by intense action sequences reminiscent of the one man army style of action movies from the 80s, such as those featuring Sylvester Stallone or Arnold Schwarzenegger. The film combines hand-to-hand combat and gunfights, creating a brutal and bloody spectacle that enhances the revenge narrative, while also expanding on the complexity of the story compared to the original movie.\n",
            "————————————————————————————————————————————————————————————\n",
            "Q: How does Keanu Reeves' performance contribute to the success of the John Wick franchise, particularly in the context of its intense action sequences?\n",
            "GT: Keanu Reeves' performance is pivotal to the success of the John Wick franchise. His portrayal of the titular character is marked by a slickness and confidence that elevates the film beyond its seemingly straightforward revenge plot. Reeves' ability to embody 'cool' with such assurance makes the character of John Wick believable, even in the face of implausible situations where he dispatches countless adversaries with extreme force. This performance, combined with meticulously choreographed action sequences, creates a dynamic and engaging experience for the audience. The nightclub showdown, in particular, is highlighted as a standout scene that showcases the intensity and brilliance of the action choreography, further cementing the film's status as a top-tier action movie. Reeves' return to the action genre with John Wick is seen as a welcome one, contributing significantly to the franchise's acclaim and setting new standards for action films.\n",
            "————————————————————————————————————————————————————————————\n",
            "Q: What are the contrasting opinions on the John Wick franchise, particularly focusing on the action sequences and plot, as seen in both positive and negative reviews?\n",
            "GT: The John Wick franchise receives contrasting opinions, particularly regarding its action sequences and plot. A positive review praises the third installment for its high-quality action sequences, inventive choreography, and engaging pacing, highlighting scenes such as horse and motorbike chases, a Moroccan brawl with fighting dogs, and top-notch hand-to-hand combat featuring actors like Mark Dacascos. This review considers the film hard to beat in terms of sheer enjoyment and eagerly anticipates the next installment. In contrast, a negative review criticizes the franchise, particularly the fourth installment, for its unrealistic plot and repetitive fight scenes. The reviewer finds the action sequences boring, citing numerous judo throws and headshots, and expresses disbelief at the protagonist's ability to survive major injuries only to succumb to minor wounds. This review also questions the authenticity of high ratings on platforms like IMDB, suggesting they are inflated.\n",
            "————————————————————————————————————————————————————————————\n",
            "Q: How John Wick movie show Hollywood action films with intense action and standout performances?\n",
            "GT: The John Wick movie exemplifies Hollywood action films by delivering a relentless, pulse-pounding thriller that is both intense and emotionally engaging. The film features standout performances, particularly by Keanu Reeves as John Wick, who navigates a plot filled with high-stakes action sequences. The storyline involves John Wick being forced out of retirement to honor a marker, leading to a series of intense confrontations and a seven-million dollar contract on his life. This film is noted for its meticulous choreography and intensity, aligning it with other classic action films like TAKEN and THE RAID.\n",
            "————————————————————————————————————————————————————————————\n",
            "Q: How John Wick: Chapter 4 improve on Chapter 3 - Parabellum and what make Keanu Reeves and Chad Stahelski so great?\n",
            "GT: John Wick: Chapter 4 improves on Chapter 3 - Parabellum by continuing the tradition of intense action sequences from the very start to the end of the film, further solidifying Keanu Reeves as the greatest martial arts action star of all time. Additionally, it highlights the exceptional pairing of Reeves and Director Chad Stahelski as the greatest martial arts action duo of modern times. Chapter 3 - Parabellum was noted for its insane style and memorable scenes, such as Keanu Reeves on horseback shooting at motorcyclists, which set high expectations for the sequel.\n",
            "————————————————————————————————————————————————————————————\n",
            "Q: Why John Wick 4 better than John Wick 3?\n",
            "GT: The reviewer believes 'John Wick: Chapter 4' is the best the series has to offer, describing it as a wild ride, while 'John Wick: Chapter 3 - Parabellum' is praised for its insane style and standout action sequences, such as Keanu Reeves on horseback shooting at motorcyclists. Despite both films being well-received, the reviewer personally rates 'Chapter 4' higher.\n",
            "————————————————————————————————————————————————————————————\n",
            "Q: How has the John Wick franchise set a standard for action films in Hollywood, and what role did Chad Stahelski and Keanu Reeves play in this achievement?\n",
            "GT: The John Wick franchise has set a standard for action films in Hollywood by delivering expertly choreographed, shot, and edited action sequences. This achievement is largely attributed to Chad Stahelski and Keanu Reeves, whose knowledge of the technical aspects of shooting action has allowed them to create films that are now considered exemplary in the genre. Their work has elevated the franchise to be a benchmark for great action filmmaking, culminating in the highly anticipated fourth film, which continues to deliver with creativity and excellence.\n",
            "————————————————————————————————————————————————————————————\n",
            "Q: How does Keanu Reeves' portrayal of John Wick contribute to the film's appeal despite criticisms of a weak plot in the sequels?\n",
            "GT: Keanu Reeves' portrayal of John Wick significantly contributes to the film's appeal by embodying the character of the Boogeyman with intensity and skill. Despite criticisms of a weak plot in the sequels, as noted in the review of the third movie, Keanu's performance remains a standout element. His ability to convincingly portray a retired hit-man seeking revenge adds depth to the action sequences, making them engaging for audiences. This is evident from the positive reception of his role in the first movie, where his character's personal loss and subsequent quest for vengeance drive the narrative, capturing the audience's attention.\n",
            "————————————————————————————————————————————————————————————\n"
          ]
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator.from_langchain(\n",
        "    llm=make_chat_model(),\n",
        "    embedding_model=embeddings\n",
        ")\n",
        "\n",
        "testset = generator.generate_with_langchain_docs(\n",
        "    documents=documents,\n",
        "    testset_size=12,\n",
        "    with_debugging_logs=False\n",
        ")\n",
        "\n",
        "# Accept only samples with a valid ground truth. Some will not due to rate limit errors, so I also increased the testset size above.\n",
        "valid_samples = [s for s in testset.samples if s.eval_sample.reference is not None]\n",
        "\n",
        "# print the testset (Question and Grounded Truth)\n",
        "for sample in testset.samples:\n",
        "    print(\"Q:\", sample.eval_sample.user_input)\n",
        "    print(\"GT:\", sample.eval_sample.reference)\n",
        "    print(\"—\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save the test questions for potential reuse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"testset.json\", \"w\") as f:\n",
        "    json.dump([s.model_dump() for s in testset.samples], f, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate answers and metrics using each of the seven retrievers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create this `safe_generate(...)` function to avoid rate and token limit issues.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def safe_generate(llm, question, retries=3, delay=2):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            result = llm.invoke(question)\n",
        "            return result.content if hasattr(result, \"content\") else str(result)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Retry {attempt+1} for generation failed: {e}\")\n",
        "            time.sleep(delay)\n",
        "    return \"Generation failed\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the common method for generating and evaluating answers to each question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    answer_relevancy,\n",
        "    faithfulness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    answer_correctness,\n",
        ")\n",
        "\n",
        "\n",
        "def evaluate_per_sample(samples, retriever, llm, embeddings, name=\"naive\", sleep=3):\n",
        "    scores = {\n",
        "        \"answer_correctness\": [],\n",
        "        \"answer_relevancy\": [],\n",
        "        \"faithfulness\": [],\n",
        "        \"context_recall\": [],\n",
        "        \"context_precision\": [],\n",
        "    }\n",
        "\n",
        "    for i, sample in enumerate(samples, 1):\n",
        "        question = sample.eval_sample.user_input\n",
        "        ground_truth = sample.eval_sample.reference\n",
        "\n",
        "        docs = retriever.get_relevant_documents(question)\n",
        "        contexts = [doc.page_content for doc in docs]\n",
        "        \n",
        "        # Use safe LLM generation\n",
        "        answer = safe_generate(llm, question)\n",
        "        \n",
        "        eval_ds = Dataset.from_dict({\n",
        "            \"question\": [question],\n",
        "            \"contexts\": [contexts],\n",
        "            \"answer\": [answer],\n",
        "            \"ground_truth\": [ground_truth],\n",
        "        })\n",
        "\n",
        "        try:\n",
        "            result = evaluate(\n",
        "                dataset=eval_ds,\n",
        "                metrics=[\n",
        "                    answer_relevancy,\n",
        "                    faithfulness,\n",
        "                    context_recall,\n",
        "                    context_precision,\n",
        "                    answer_correctness,\n",
        "                ],\n",
        "                llm=llm,\n",
        "                embeddings=embeddings\n",
        "            )\n",
        "            for k in scores:\n",
        "                scores[k].append(result[k])\n",
        "            print(f\"[{name}] ✅ {i}/{len(samples)} complete\")\n",
        "        except Exception as e:\n",
        "            print(f\"[{name}] ❌ {i}/{len(samples)} failed: {e}\")\n",
        "            for k in scores:\n",
        "                scores[k].append(None)\n",
        "\n",
        "        time.sleep(sleep)  # ⏱️ Control rate limit manually\n",
        "\n",
        "    return scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Summarize the scores after each run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def summarize_scores(scores_dict, name=\"Naive\"):\n",
        "    summary = {k: round(np.nanmean([v for v in values if v is not None]), 4)\n",
        "               for k, values in scores_dict.items()}\n",
        "    return pd.DataFrame([summary], index=[name])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run answer generation for every retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a collection of the seven retriever types.\n",
        "retrievers = {\n",
        "    \"naive\": naive_retriever,\n",
        "    \"bm25\": bm25_retriever,\n",
        "    \"compression\": compression_retriever,\n",
        "    \"multi_query\": multi_query_retriever,\n",
        "    \"parent\": parent_document_retriever,\n",
        "    \"ensemble\": ensemble_retriever,\n",
        "    \"semantic\": semantic_retriever,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Evaluating retriever: naive\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5p/gq47dsys3k5663k1r5z8s3c40000gn/T/ipykernel_77341/1841367254.py:15: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
            "  return ChatOpenAI(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1554a7f3173d463695690540744b9db8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] ✅ 1/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "245b264c9db646829a26459b7fa9507b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] ✅ 2/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be912d6c8be94b868a2ec9b0fc38d895",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] ✅ 3/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60c102407730413bb40bdee54d3dc4f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] ✅ 4/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5d774d53da54a82aa28b98dd08b46d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] ✅ 5/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1718c197aef40e2b0a241b0d5f763d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] ✅ 6/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5b064218ece47829121bf4c7412b15a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] ✅ 7/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b7d21c010d44655a2dd176321edddbe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] ✅ 8/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae5e49528f6e4d24904b270f813c5f66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] ✅ 9/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1da9f8b5318847b2820db7a3a4e99d0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] ✅ 10/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58e7268932b444cd9ce20e8fbb71c56f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] ✅ 11/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3f2655722c248a19ae27301eeb04a60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[naive] ✅ 12/12 complete\n",
            "\n",
            "🔍 Evaluating retriever: bm25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5p/gq47dsys3k5663k1r5z8s3c40000gn/T/ipykernel_77341/1841367254.py:15: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
            "  return ChatOpenAI(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2148426403614cf486d3541ea895b682",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] ✅ 1/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96891457bf294ed593996c6b049b0a0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] ✅ 2/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f74d891ddc224efe9424a90f63624bc4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] ✅ 3/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24f389d2a02745c596ad980edd6f0fc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] ✅ 4/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1699109848b44b4995349bf503cdb91d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] ✅ 5/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fd7c025e6a94311a4d6522b8a8e080a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] ✅ 6/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "129446ccc0214716aaee7a62ed7e1821",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] ✅ 7/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ac0b9e6295b434086a55af3f2e7d595",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] ✅ 8/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bae3c2d922dd4a9f81b979ec7b0d6109",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] ✅ 9/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "030ff22da7df47ce8df34462ad52c4b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] ✅ 10/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82c29f0d952f489d90ec101f9f3b4c5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] ✅ 11/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74fdd43673864ba7bae49741236dd7ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[bm25] ✅ 12/12 complete\n",
            "\n",
            "🔍 Evaluating retriever: compression\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5p/gq47dsys3k5663k1r5z8s3c40000gn/T/ipykernel_77341/1841367254.py:15: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
            "  return ChatOpenAI(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d183fa0cbc2487297e58a744c009b72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] ✅ 1/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66f59c7d2bb1421abf21305c2ffc30a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] ✅ 2/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8650db6111854ec595ab8c05b81e91ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] ✅ 3/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f62ac3808434be58016e6a335637dcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] ✅ 4/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "137b974419b043d4b91a44d4a18476a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] ✅ 5/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a74c7df78db349b982ada62bf6e776bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] ✅ 6/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aff5e1f3233d4995bf9a714674d96168",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] ✅ 7/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8ca18bf6266458dab542960d2f44866",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] ✅ 8/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afe1d6e0185b4ff78ed97295f87064f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] ✅ 9/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a5615681e70477c8759d05bd9fb93f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] ✅ 10/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b2f96308fa34273b94638818f3dcc85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] ✅ 11/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ae8e1390ded42478a873c8d09877357",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[compression] ✅ 12/12 complete\n",
            "\n",
            "🔍 Evaluating retriever: multi_query\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5p/gq47dsys3k5663k1r5z8s3c40000gn/T/ipykernel_77341/1841367254.py:15: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
            "  return ChatOpenAI(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d7d535691d1465294afda5b553ae3cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] ✅ 1/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1b24ca96b3b4767847ceb7b90d68d4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] ✅ 2/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51bdbba9082942a5ab962033fbe8f578",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] ✅ 3/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ba7c524467a4f23bfd3b381c9d686ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] ✅ 4/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b63f7ac984694df5a72a441fbfb9ab90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] ✅ 5/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7dbdd9d61af4dfcbfe286e0a5ec369e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] ✅ 6/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30b47b95b2ee4633b481a06f6feb6e49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] ✅ 7/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ee981e2dbee44dd95a5ab4fa08591c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] ✅ 8/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd418a539a5c4f32a10b5cc3c5ebe6d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] ✅ 9/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3c98fe5d1e341a8ac20ae93d26ab23b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] ✅ 10/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d90daf24edb14356a312999d02753355",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] ✅ 11/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "731f0730c701479685c709e730b196fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[multi_query] ✅ 12/12 complete\n",
            "\n",
            "🔍 Evaluating retriever: parent\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5p/gq47dsys3k5663k1r5z8s3c40000gn/T/ipykernel_77341/1841367254.py:15: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
            "  return ChatOpenAI(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c797777392a46488861bb13a07b7136",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] ✅ 1/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "967ada5bff0e433c9d397eac354c09e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] ✅ 2/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a78a579d68448c3b523d85afe751635",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] ✅ 3/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b162867233804411ac2d4d50f7fe2ee0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] ✅ 4/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fa5ab20eadd46c48e0ef37d1840ce5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] ✅ 5/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d3d565402374ac68e2eebe4dff6cb22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] ✅ 6/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ca02f575f064e178c03ed69d760b740",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] ✅ 7/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f6a2d5ac2464e159fe9e9087032f71b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] ✅ 8/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e57fe06bc8ab477e80f509f59a23f6bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] ✅ 9/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "294273a13b5543e09dcea7b3abde30e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] ✅ 10/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ca92c1d92544c08a5d2b59f8cc0e02b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] ✅ 11/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e32f13a036c43b688ce1dabf52ececc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parent] ✅ 12/12 complete\n",
            "\n",
            "🔍 Evaluating retriever: ensemble\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5p/gq47dsys3k5663k1r5z8s3c40000gn/T/ipykernel_77341/1841367254.py:15: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
            "  return ChatOpenAI(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f1c6b03fc354b5699ef5e284d41ba99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] ✅ 1/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a723343c48d41dea96cbabe17644034",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] ✅ 2/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e29f31766a7a4c7485ac7031a8ac4bab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] ✅ 3/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56c17d77f20b43acb58c86d7eb37116a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] ✅ 4/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb98de1dd92f43f88d9cb656ebd326a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] ✅ 5/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8bb381e64fa4bc99e0587a29f8667ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] ✅ 6/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a116745f905e4abd81e759f2b4b677ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] ✅ 7/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d1cd8ade0d7430cbb13c986037be30c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] ✅ 8/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ad24dd0d7b0432fbe913801682e02c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] ✅ 9/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f0c4d1bf3c745458988a4196fd90e43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] ✅ 10/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60ab99dd34954d81ab9efe642672e5e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] ✅ 11/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d029cf767b2431490c069189153498f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ensemble] ✅ 12/12 complete\n",
            "\n",
            "🔍 Evaluating retriever: semantic\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5p/gq47dsys3k5663k1r5z8s3c40000gn/T/ipykernel_77341/1841367254.py:15: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
            "  return ChatOpenAI(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68da480bd920465d8768059559b6c759",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] ✅ 1/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cf84fa2f008407bb3a5d60ea3d16e4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] ✅ 2/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d80e74e3a7df45b2b7daa29cfba550c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] ✅ 3/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4260d68358964d469fa6b4a1433c4ea3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] ✅ 4/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "376d5b8e967446a9b39b7374a2326aa5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] ✅ 5/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15093cf238a44a60a76d6d6bf64aa0b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] ✅ 6/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca63c2896c134fd2a78a0913e39a851e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] ✅ 7/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59a335d9eb5941c3848fcbdf44be0d98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] ✅ 8/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50d1fbfb6fa144d7a17418a3aa4a6ff5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] ✅ 9/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d9620d347ef4b31b6ec7d5bb8963a2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] ✅ 10/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c6dafbf1ad14e07b77986e0319ca766",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] ✅ 11/12 complete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27c9853192294009b1e5f3e09707dcba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[semantic] ✅ 12/12 complete\n"
          ]
        }
      ],
      "source": [
        "all_scores = {}\n",
        "all_dataframes = []\n",
        "\n",
        "for retriever_name, retriever in retrievers.items():\n",
        "    print(f\"\\n🔍 Evaluating retriever: {retriever_name}\")\n",
        "\n",
        "    scores = evaluate_per_sample(\n",
        "        samples=valid_samples,\n",
        "        retriever=retriever,\n",
        "        llm=make_chat_model(retriever_name=retriever_name, model_name=\"gpt-4o\"),\n",
        "        embeddings=embeddings,\n",
        "        name=retriever_name,\n",
        "        sleep=4\n",
        "    )\n",
        "\n",
        "    # Store scores and summarized DataFrame\n",
        "    all_scores[retriever_name] = scores\n",
        "    df = summarize_scores(scores, name=retriever_name.capitalize())\n",
        "    all_dataframes.append(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Combine the dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             answer_correctness  answer_relevancy  faithfulness  \\\n",
            "Naive                    0.3735            0.7773        0.4972   \n",
            "Bm25                     0.3926            0.7761        0.3187   \n",
            "Compression              0.4080            0.7761        0.3448   \n",
            "Multi_query              0.3848            0.7734        0.4938   \n",
            "Parent                   0.3646            0.7760        0.2813   \n",
            "Ensemble                 0.3335            0.7734        0.6159   \n",
            "Semantic                 0.3465            0.7771        0.4461   \n",
            "\n",
            "             context_recall  context_precision  \n",
            "Naive                0.8819             0.8706  \n",
            "Bm25                 0.7778             0.7222  \n",
            "Compression          0.8819             1.0000  \n",
            "Multi_query          0.8264             0.7826  \n",
            "Parent               0.5694             0.8056  \n",
            "Ensemble             0.9236             0.7999  \n",
            "Semantic             0.8542             0.6727  \n"
          ]
        }
      ],
      "source": [
        "# Combine all dataframes into a single dataframe\n",
        "\n",
        "final_df = pd.concat(all_dataframes, axis=0)\n",
        "\n",
        "print(final_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Retrieve LangSmith metrics and append to the RAGAS metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "def get_langsmith_metrics(project_name, model_name=\"gpt-4o\"):\n",
        "    client = Client()\n",
        "    runs = list(client.list_runs(project_name=project_name, run_type=\"llm\"))\n",
        "\n",
        "    latencies = []\n",
        "    costs = []\n",
        "\n",
        "    for run in runs:\n",
        "        full_run = client.read_run(run.id)\n",
        "\n",
        "        if full_run.start_time and full_run.end_time:\n",
        "            duration = (full_run.end_time - full_run.start_time).total_seconds()\n",
        "            latencies.append(duration)\n",
        "\n",
        "        usage = (\n",
        "            full_run.outputs\n",
        "            .get(\"llm_output\", {})\n",
        "            .get(\"token_usage\", {})\n",
        "        )\n",
        "\n",
        "        input_tokens = usage.get(\"prompt_tokens\", 0)\n",
        "        output_tokens = usage.get(\"completion_tokens\", 0)\n",
        "\n",
        "        if \"gpt-4o\" in model_name:\n",
        "            cost = (input_tokens / 1000) * 0.005 + (output_tokens / 1000) * 0.015\n",
        "        elif \"gpt-3.5\" in model_name:\n",
        "            cost = (input_tokens / 1000) * 0.0015 + (output_tokens / 1000) * 0.002\n",
        "        else:\n",
        "            cost = 0\n",
        "\n",
        "        costs.append(cost)\n",
        "\n",
        "    avg_latency = round(sum(latencies) / len(latencies), 3) if latencies else None\n",
        "    total_cost = round(sum(costs), 4) if costs else None\n",
        "\n",
        "    return avg_latency, total_cost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing tracing information for ragas-eval-naive\n",
            "Processing tracing information for ragas-eval-bm25\n",
            "Processing tracing information for ragas-eval-compression\n",
            "Processing tracing information for ragas-eval-multi_query\n",
            "Processing tracing information for ragas-eval-parent\n",
            "Processing tracing information for ragas-eval-ensemble\n",
            "Processing tracing information for ragas-eval-semantic\n"
          ]
        }
      ],
      "source": [
        "latencies = []\n",
        "costs = []\n",
        "\n",
        "for name in retrievers.keys():\n",
        "    project_name = f\"ragas-eval-{name}\"\n",
        "    print(\"Processing tracing information for\", project_name)\n",
        "    latency, cost = get_langsmith_metrics(project_name)\n",
        "    latencies.append(latency)\n",
        "    costs.append(cost)\n",
        "\n",
        "final_df[\"avg_latency_s\"] = latencies\n",
        "final_df[\"total_cost_usd\"] = costs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Latency Values:  [6.424, 6.254, 6.875, 6.461, 6.401, 6.437, 6.452]\n",
            "Cost Values:  [0.2385, 0.1605, 0.146, 0.147, 0.1475, 0.1479, 0.1478]\n",
            "             answer_correctness  answer_relevancy  faithfulness  \\\n",
            "Naive                    0.3735            0.7773        0.4972   \n",
            "Bm25                     0.3926            0.7761        0.3187   \n",
            "Compression              0.4080            0.7761        0.3448   \n",
            "Multi_query              0.3848            0.7734        0.4938   \n",
            "Parent                   0.3646            0.7760        0.2813   \n",
            "Ensemble                 0.3335            0.7734        0.6159   \n",
            "Semantic                 0.3465            0.7771        0.4461   \n",
            "\n",
            "             context_recall  context_precision  avg_latency_s  total_cost_usd  \n",
            "Naive                0.8819             0.8706          6.424          0.2385  \n",
            "Bm25                 0.7778             0.7222          6.254          0.1605  \n",
            "Compression          0.8819             1.0000          6.875          0.1460  \n",
            "Multi_query          0.8264             0.7826          6.461          0.1470  \n",
            "Parent               0.5694             0.8056          6.401          0.1475  \n",
            "Ensemble             0.9236             0.7999          6.437          0.1479  \n",
            "Semantic             0.8542             0.6727          6.452          0.1478  \n"
          ]
        }
      ],
      "source": [
        "print(\"Latency Values: \", latencies)\n",
        "print(\"Cost Values: \", costs)\n",
        "\n",
        "print(final_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Prepare the final table output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n",
            "|                    | Group     |   Naive |   Bm25 |   Compression |   Multi_query |   Parent |   Ensemble |   Semantic |\n",
            "+====================+===========+=========+========+===============+===============+==========+============+============+\n",
            "| context_precision  | Retriever |  0.8706 | 0.7222 |        1      |        0.7826 |   0.8056 |     0.7999 |     0.6727 |\n",
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n",
            "| context_recall     | Retriever |  0.8819 | 0.7778 |        0.8819 |        0.8264 |   0.5694 |     0.9236 |     0.8542 |\n",
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n",
            "| faithfulness       | Retriever |  0.4972 | 0.3187 |        0.3448 |        0.4938 |   0.2813 |     0.6159 |     0.4461 |\n",
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n",
            "| answer_relevancy   | Answer    |  0.7773 | 0.7761 |        0.7761 |        0.7734 |   0.776  |     0.7734 |     0.7771 |\n",
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n",
            "| answer_correctness | Answer    |  0.3735 | 0.3926 |        0.408  |        0.3848 |   0.3646 |     0.3335 |     0.3465 |\n",
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n",
            "| avg_latency_s      | Infra     |  6.424  | 6.254  |        6.875  |        6.461  |   6.401  |     6.437  |     6.452  |\n",
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n",
            "| total_cost_usd     | Infra     |  0.2385 | 0.1605 |        0.146  |        0.147  |   0.1475 |     0.1479 |     0.1478 |\n",
            "+--------------------+-----------+---------+--------+---------------+---------------+----------+------------+------------+\n"
          ]
        }
      ],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# switch the columns and the rows so that the metrics are the rows and the retrievers are the columns.\n",
        "final_df = final_df.T\n",
        "\n",
        "# Define groups\n",
        "retriever_metrics = [\"context_precision\", \"context_recall\", \"faithfulness\"]\n",
        "answer_metrics = [\"answer_relevancy\", \"answer_correctness\"]\n",
        "infra_metrics = [\"avg_latency_s\", \"total_cost_usd\"]\n",
        "\n",
        "# Reorder with blank rows as visual separators\n",
        "ordered_rows = (\n",
        "    retriever_metrics +\n",
        "    answer_metrics +\n",
        "    infra_metrics\n",
        ")\n",
        "\n",
        "# Reindex with visual grouping\n",
        "df_grouped = final_df.reindex(ordered_rows)\n",
        "\n",
        "# Add a \"Group\" column for display/printing\n",
        "group_labels = {\n",
        "    \"context_precision\": \"Retriever\",\n",
        "    \"context_recall\": \"Retriever\",\n",
        "    \"faithfulness\": \"Retriever\",\n",
        "    \"answer_relevancy\": \"Answer\",\n",
        "    \"answer_correctness\": \"Answer\",\n",
        "    \"avg_latency_s\": \"Infra\",\n",
        "    \"total_cost_usd\": \"Infra\",\n",
        "}\n",
        "\n",
        "df_grouped.insert(0, \"Group\", [group_labels.get(m, \"\") for m in df_grouped.index])\n",
        "\n",
        "\n",
        "print(tabulate(df_grouped, headers=\"keys\", tablefmt=\"grid\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final RAGAS Evaluation Results ↕️"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![RAGAS-Evaluation-Chart](assets/AIE6-S13-final_ragas_metrics_by_retriever.png)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
